# ðŸ§  Your Task: Tokenize the story from 'story.txt' using NLTK's sent_tokenize and word_tokenize functions

# Make sure required NLTK resources are available


# 1. Open and read the story text


# 2. (Optional) Remove any unwanted characters using re.sub
# For example: remove extra whitespace or punctuation symbols
clean_story = None  # Keep common sentence characters

# 3. Tokenize the story into sentences
# TODO: Replace the line below with a call to sent_tokenize
sentences = []

# 4. Tokenize the story into words
# TODO: Replace the line below with a call to word_tokenize
words = []

# 5. Print results
print("=== Sentences ===")
print(sentences)
print("\n=== Words ===")
print(words)
